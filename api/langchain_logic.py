# api/langchain_logic.py
import os
from langchain_openai import ChatOpenAI


# Securely retrieve your OpenAI API key from environment variables
openai_api_key = os.environ.get('OPENAI_API_KEY')

# Initialize the OpenAI LLM with your API key and desired parameters
llm = ChatOpenAI(
    openai_api_key=openai_api_key,
    model_name='gpt-3.5-turbo',
    temperature=0.7
)

def process_message(conversation):
    """
    Send the conversation history to the language model and return the response text.
    """
    try:
        # Use the LLM to generate a response
        response = llm.invoke(conversation)  # Passing the conversation history
        # Access the content of the response
        if response:
            return response.content
        else:
            return "No response generated by the model."
    except Exception as e:
        print(f"An error occurred: {e}")
        return f"Sorry, an error occurred while processing your message. {str(e)}"